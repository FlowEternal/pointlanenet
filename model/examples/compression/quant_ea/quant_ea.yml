general:
    backend: pytorch  # pytorch | tensorflow


pipeline: [nas, fully_train]


nas:
    pipe_step:
        type: SearchPipeStep
    dataset:
        type: Cifar10
        common:
            data_path: /cache/datasets/cifar10/
            train_portion: 0.9  
        train:
            batch_size: 128
        test:
            batch_size: 256
    search_algorithm:
        type: QuantEA
        codec: QuantCodec
        policy:
            length: 40
            num_generation: 50
            num_individual: 16
            random_samples: 32
    search_space:
        type: SearchSpace
        modules: ['backbone', 'head']
        bit_candidates: [4, 8]
        backbone:
            type: ResNetGeneral
            base_depth: 20
            base_channel: 16
            stage: 3
        head:
            type: LinearClassificationHead
            base_channel: 64
            num_classes: 10
    trainer:
        type: Trainer
        callbacks: QuantTrainerCallback
        epochs: 1
        optimizer:
            type: SGD
            params:
                lr: 0.1
                momentum: 0.9
                weight_decay: !!float 1e-4
        lr_scheduler:
            type: MultiStepLR
            params:
                milestones: [5, 10, 15]
                gamma: 0.1
        seed: 10
        save_weight: False
        limits:
            flop_range: [!!float 0, !!float 1e10]


fully_train:
    pipe_step:
        type: TrainPipeStep
        models_folder: "{local_base_path}/output/nas/"
    dataset:
        ref: nas.dataset
        common:
            train_portion: 1.0
        train: 
            shuffle: True
    trainer:
        ref: nas.trainer
        callbacks: QuantTrainerCallback
        epochs: 400
        lr_scheduler:
            type: MultiStepLR
            params:
                milestones: [200, 300, 375]
                gamma: 0.1
    evaluator:
        type: Evaluator
        host_evaluator:
            type: HostEvaluator
            metric:
                type: accuracy
